{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-03T17:02:47.849485Z",
     "iopub.status.busy": "2025-04-03T17:02:47.849234Z",
     "iopub.status.idle": "2025-04-03T17:02:53.158548Z",
     "shell.execute_reply": "2025-04-03T17:02:53.157787Z",
     "shell.execute_reply.started": "2025-04-03T17:02:47.849464Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "Tesla T4\n",
      "Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.device_count())  # Should print 2\n",
    "print(torch.cuda.get_device_name(0))  \n",
    "print(torch.cuda.get_device_name(1))\n",
    "\n",
    "# cuda is a technology from NVIDIA that allows you to use your graphics card (GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T17:02:55.289080Z",
     "iopub.status.busy": "2025-04-03T17:02:55.288742Z",
     "iopub.status.idle": "2025-04-03T17:02:58.594057Z",
     "shell.execute_reply": "2025-04-03T17:02:58.593402Z",
     "shell.execute_reply.started": "2025-04-03T17:02:55.289053Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import kagglehub     # dataset ko download krne mein help krta hai \n",
    "import torch         # used to tain and build a AI model\n",
    "import torch.nn as nn    #to build structure of AI model like input layer,output layer, hidden layer\n",
    "import torch.optim as optim      #\n",
    "import torchvision.transforms as transforms    #helps you preprocess your images \n",
    "import torchvision.models as models            #gives you access to pre-trained AI models for image recognition, like ResNet\n",
    "from torchvision.datasets import ImageFolder   #This helps you load images from folders \n",
    "from torch.utils.data import DataLoader        #organize your dataset into smaller batches so you can feed it to your model in chunks.\n",
    "from einops import rearrange       # smart reshapeing tools\n",
    "import os         #helps to acces files from system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T17:03:04.524699Z",
     "iopub.status.busy": "2025-04-03T17:03:04.524271Z",
     "iopub.status.idle": "2025-04-03T17:03:04.636657Z",
     "shell.execute_reply": "2025-04-03T17:03:04.635879Z",
     "shell.execute_reply.started": "2025-04-03T17:03:04.524672Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /kaggle/input/new-plant-diseases-dataset\n"
     ]
    }
   ],
   "source": [
    "# Download latest dataset version\n",
    "path = kagglehub.dataset_download(\"vipoooool/new-plant-diseases-dataset\")\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T17:03:06.221077Z",
     "iopub.status.busy": "2025-04-03T17:03:06.220594Z",
     "iopub.status.idle": "2025-04-03T17:03:06.227581Z",
     "shell.execute_reply": "2025-04-03T17:03:06.226687Z",
     "shell.execute_reply.started": "2025-04-03T17:03:06.221036Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T17:03:07.502130Z",
     "iopub.status.busy": "2025-04-03T17:03:07.501837Z",
     "iopub.status.idle": "2025-04-03T17:03:07.519579Z",
     "shell.execute_reply": "2025-04-03T17:03:07.518945Z",
     "shell.execute_reply.started": "2025-04-03T17:03:07.502108Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents of dataset: ['valid', 'train']\n"
     ]
    }
   ],
   "source": [
    "# Dataset paths\n",
    "dataset_path = \"/kaggle/input/new-plant-diseases-dataset/New Plant Diseases Dataset(Augmented)/New Plant Diseases Dataset(Augmented)\"\n",
    "print(\"Contents of dataset:\", os.listdir(dataset_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T17:03:09.434797Z",
     "iopub.status.busy": "2025-04-03T17:03:09.434479Z",
     "iopub.status.idle": "2025-04-03T17:03:09.438738Z",
     "shell.execute_reply": "2025-04-03T17:03:09.438053Z",
     "shell.execute_reply.started": "2025-04-03T17:03:09.434769Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),    # convert all the image in same size\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])    # adjust color values of the image \n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T17:03:17.257691Z",
     "iopub.status.busy": "2025-04-03T17:03:17.257407Z",
     "iopub.status.idle": "2025-04-03T17:04:55.537436Z",
     "shell.execute_reply": "2025-04-03T17:04:55.536787Z",
     "shell.execute_reply.started": "2025-04-03T17:03:17.257670Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Load datasets\n",
    "train_dataset = ImageFolder(root=f\"{dataset_path}/train\", transform=transform)\n",
    "val_dataset = ImageFolder(root=f\"{dataset_path}/valid\", transform=transform)\n",
    "# dataset ko load krta hai file se aur usee clean krta hai useing transform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T17:05:53.765560Z",
     "iopub.status.busy": "2025-04-03T17:05:53.765231Z",
     "iopub.status.idle": "2025-04-03T17:05:53.769650Z",
     "shell.execute_reply": "2025-04-03T17:05:53.768795Z",
     "shell.execute_reply.started": "2025-04-03T17:05:53.765535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Data loaders (optimized)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=4, pin_memory=True)\n",
    "\n",
    "# dataset ko load krta hai aur fir batch size fix8 mtlb per turn pe model 8 photos ko pic krege for taring\n",
    "# dataset jldi load hoo jaye uske liye 4 CPU threads  use krr rhe hai \n",
    "#pin memory train ko speed krr rha hai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T17:05:55.822976Z",
     "iopub.status.busy": "2025-04-03T17:05:55.822632Z",
     "iopub.status.idle": "2025-04-03T17:05:55.827086Z",
     "shell.execute_reply": "2025-04-03T17:05:55.826316Z",
     "shell.execute_reply.started": "2025-04-03T17:05:55.822940Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 38\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_classes = len(train_dataset.classes)\n",
    "print(\"Number of classes:\", num_classes)\n",
    "\n",
    "#to detect the number of classes in training dataset we can use len function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T17:05:58.103050Z",
     "iopub.status.busy": "2025-04-03T17:05:58.102694Z",
     "iopub.status.idle": "2025-04-03T17:05:58.107428Z",
     "shell.execute_reply": "2025-04-03T17:05:58.106769Z",
     "shell.execute_reply.started": "2025-04-03T17:05:58.103023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CNN Feature Extractor (ResNet50)\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "        base_model = models.resnet50(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(base_model.children())[:-2])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.feature_extractor(x)  # Output: (batch_size, 2048, 7, 7)\n",
    "    \n",
    "    # ResNet50 pretrained model use krr rhe hai for feature extraction.\n",
    "    # defining class for feature extraction \n",
    "    # _int_ constructor use krr rhe hai \n",
    "    # super function model ko proper neural network ki tarah behave krne mein help krr rha hai \n",
    "    # yaha sirf hamm CNN ka feature extration part use krr rhe esliye -2 kiye hai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T17:05:59.978995Z",
     "iopub.status.busy": "2025-04-03T17:05:59.978707Z",
     "iopub.status.idle": "2025-04-03T17:05:59.984178Z",
     "shell.execute_reply": "2025-04-03T17:05:59.983293Z",
     "shell.execute_reply.started": "2025-04-03T17:05:59.978975Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Transformer Encoder Block\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, dim, heads=8, ff_dim=2048, dropout=0.1):\n",
    "        super(TransformerEncoderBlock, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim=dim, num_heads=heads, dropout=dropout)\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, dim)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(dim)    #•\tSocho: Yeh input vector ko le raha hai aur usse ek badi feature space mein map kar raha hai — \n",
    "                                            #      jahan pe model zyada complex patterns samajh sakta hai.\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_out, _ = self.self_attn(x, x, x)\n",
    "        x = self.norm1(x + attn_out)\n",
    "        ffn_out = self.ffn(x)   \n",
    "        return self.norm2(x + ffn_out)         #Maan lo tumhare paas ek photo hai. Tum us photo ka \n",
    "                                            #zoom-in version dekhte ho (expand karte ho), Fir \n",
    "                                            #important features mark karte ho (ReLU), \n",
    "                                            # Aur fir zoom-out karke sirf important cheezein lekar aage bhejte ho (compress back).\n",
    "    \n",
    "\n",
    "    #\tWhat is a Transformer Encoder Block?\n",
    "#Looks at all parts of the input at once\n",
    "#Figures out which parts are important and how they relate to each other\n",
    "\t#Processes those relationships to better understand the image or data\n",
    "\n",
    "    # dim= size of each input vector\n",
    "    # heads = model kitne different types se data ko rad krr rhe hai \n",
    "    # ff_dim= size of inner feedforward layer\n",
    "    #\tself.norm1 = nn.LayerNorm(dim)\n",
    "#This normalizes the data (makes it consistent) after attention. Helps the model stay stable and learn better.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T17:06:02.398870Z",
     "iopub.status.busy": "2025-04-03T17:06:02.398539Z",
     "iopub.status.idle": "2025-04-03T17:06:02.404457Z",
     "shell.execute_reply": "2025-04-03T17:06:02.403479Z",
     "shell.execute_reply.started": "2025-04-03T17:06:02.398845Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CNN + Transformer Hybrid Model\n",
    "class CNNTransformerModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNTransformerModel, self).__init__()\n",
    "        self.cnn = CNNFeatureExtractor()\n",
    "        self.patch_dim = 2048\n",
    "        self.seq_length = 7 * 7\n",
    "        self.transformer = TransformerEncoderBlock(dim=self.patch_dim, heads=8, ff_dim=2048)\n",
    "        self.fc = nn.Linear(self.patch_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        cnn_features = self.cnn(x)\n",
    "        patches = rearrange(cnn_features, \"b c h w -> (h w) b c\")\n",
    "        transformer_out = self.transformer(patches)\n",
    "        output = self.fc(transformer_out.mean(dim=0))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T17:07:03.114556Z",
     "iopub.status.busy": "2025-04-03T17:07:03.114253Z",
     "iopub.status.idle": "2025-04-03T17:07:04.762120Z",
     "shell.execute_reply": "2025-04-03T17:07:04.761332Z",
     "shell.execute_reply.started": "2025-04-03T17:07:03.114531Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
      "100%|██████████| 97.8M/97.8M [00:00<00:00, 187MB/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): CNNTransformerModel(\n",
       "    (cnn): CNNFeatureExtractor(\n",
       "      (feature_extractor): Sequential(\n",
       "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ReLU(inplace=True)\n",
       "        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "        (4): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (5): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (6): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (3): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (4): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (5): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "        (7): Sequential(\n",
       "          (0): Bottleneck(\n",
       "            (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "            (downsample): Sequential(\n",
       "              (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "              (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            )\n",
       "          )\n",
       "          (1): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Bottleneck(\n",
       "            (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (relu): ReLU(inplace=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (transformer): TransformerEncoderBlock(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=2048, out_features=2048, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "      (ffn): Sequential(\n",
       "        (0): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((2048,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (fc): Linear(in_features=2048, out_features=38, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model with multi-GPU support\n",
    "model = CNNTransformerModel(num_classes)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    model = nn.DataParallel(model)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T17:07:18.884769Z",
     "iopub.status.busy": "2025-04-03T17:07:18.884442Z",
     "iopub.status.idle": "2025-04-03T17:07:18.889336Z",
     "shell.execute_reply": "2025-04-03T17:07:18.888513Z",
     "shell.execute_reply.started": "2025-04-03T17:07:18.884741Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Loss function & optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T17:07:21.639378Z",
     "iopub.status.busy": "2025-04-03T17:07:21.639064Z",
     "iopub.status.idle": "2025-04-03T17:07:21.646638Z",
     "shell.execute_reply": "2025-04-03T17:07:21.645815Z",
     "shell.execute_reply.started": "2025-04-03T17:07:21.639352Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=7):\n",
    "    scaler = torch.amp.GradScaler(\"cuda\")  # Updated AMP syntax\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.amp.autocast(\"cuda\"):  # Updated AMP syntax\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        correct, total = 0, 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device, non_blocking=True), labels.to(device, non_blocking=True)\n",
    "                with torch.amp.autocast(\"cuda\",enabled=False):  # Added AMP for validation\n",
    "                    outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f\"Validation Accuracy: {100 * correct / total:.2f}%\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T17:07:24.368782Z",
     "iopub.status.busy": "2025-04-03T17:07:24.368491Z",
     "iopub.status.idle": "2025-04-03T19:24:51.754303Z",
     "shell.execute_reply": "2025-04-03T19:24:51.753223Z",
     "shell.execute_reply.started": "2025-04-03T17:07:24.368760Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/6], Loss: 0.2874\n",
      "Validation Accuracy: 96.63%\n",
      "Epoch [2/6], Loss: 0.1225\n",
      "Validation Accuracy: 98.00%\n",
      "Epoch [3/6], Loss: 0.0886\n",
      "Validation Accuracy: 97.18%\n",
      "Epoch [4/6], Loss: 0.0713\n",
      "Validation Accuracy: 98.32%\n",
      "Epoch [5/6], Loss: 0.0595\n",
      "Validation Accuracy: 98.41%\n",
      "Epoch [6/6], Loss: 0.0515\n",
      "Validation Accuracy: 98.08%\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T19:25:59.706135Z",
     "iopub.status.busy": "2025-04-03T19:25:59.705756Z",
     "iopub.status.idle": "2025-04-03T19:26:00.045555Z",
     "shell.execute_reply": "2025-04-03T19:26:00.044693Z",
     "shell.execute_reply.started": "2025-04-03T19:25:59.706106Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"cnn_transformer_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T19:26:06.979790Z",
     "iopub.status.busy": "2025-04-03T19:26:06.979438Z",
     "iopub.status.idle": "2025-04-03T19:26:07.428537Z",
     "shell.execute_reply": "2025-04-03T19:26:07.427432Z",
     "shell.execute_reply.started": "2025-04-03T19:26:06.979759Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model, \"cnn_transformer_full_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T19:50:21.836331Z",
     "iopub.status.busy": "2025-04-03T19:50:21.835924Z",
     "iopub.status.idle": "2025-04-03T19:50:32.327196Z",
     "shell.execute_reply": "2025-04-03T19:50:32.326120Z",
     "shell.execute_reply.started": "2025-04-03T19:50:21.836307Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  adding: cnn_transformer_full_model.pth (deflated 7%)\n"
     ]
    }
   ],
   "source": [
    "!zip -r model.zip cnn_transformer_full_model.pth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T19:50:34.801041Z",
     "iopub.status.busy": "2025-04-03T19:50:34.800611Z",
     "iopub.status.idle": "2025-04-03T19:50:34.810089Z",
     "shell.execute_reply": "2025-04-03T19:50:34.806573Z",
     "shell.execute_reply.started": "2025-04-03T19:50:34.801006Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='model.zip' target='_blank'>model.zip</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/model.zip"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(r'model.zip')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-03T20:03:09.017403Z",
     "iopub.status.busy": "2025-04-03T20:03:09.017047Z",
     "iopub.status.idle": "2025-04-03T20:03:09.541046Z",
     "shell.execute_reply": "2025-04-03T20:03:09.540045Z",
     "shell.execute_reply.started": "2025-04-03T20:03:09.017372Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"cnn_transformer_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'einops'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptim\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorchvision\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m models\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01meinops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rearrange\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Number of classes (as per your dataset)\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'einops'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "from einops import rearrange\n",
    "import os\n",
    "\n",
    "# Number of classes (as per your dataset)\n",
    "num_classes = 38\n",
    "\n",
    "# CNN Feature Extractor (ResNet50)\n",
    "class CNNFeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNFeatureExtractor, self).__init__()\n",
    "        base_model = models.resnet50(pretrained=True)\n",
    "        self.feature_extractor = nn.Sequential(*list(base_model.children())[:-2])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.feature_extractor(x)  # Output: (batch_size, 2048, 7, 7)\n",
    "\n",
    "# Transformer Encoder Block\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, dim, heads=8, ff_dim=2048, dropout=0.1):\n",
    "        super(TransformerEncoderBlock, self).__init__()\n",
    "        self.self_attn = nn.MultiheadAttention(embed_dim=dim, num_heads=heads, dropout=dropout)\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(dim, ff_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_dim, dim)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        attn_out, _ = self.self_attn(x, x, x)\n",
    "        x = self.norm1(x + attn_out)\n",
    "        ffn_out = self.ffn(x)\n",
    "        return self.norm2(x + ffn_out)\n",
    "\n",
    "# CNN + Transformer Hybrid Model\n",
    "class CNNTransformerModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNNTransformerModel, self).__init__()\n",
    "        self.cnn = CNNFeatureExtractor()\n",
    "        self.patch_dim = 2048\n",
    "        self.seq_length = 7 * 7\n",
    "        self.transformer = TransformerEncoderBlock(dim=self.patch_dim, heads=8, ff_dim=2048)\n",
    "        self.fc = nn.Linear(self.patch_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        cnn_features = self.cnn(x)\n",
    "        patches = rearrange(cnn_features, \"b c h w -> (h w) b c\")\n",
    "        transformer_out = self.transformer(patches)\n",
    "        output = self.fc(transformer_out.mean(dim=0))\n",
    "        return output\n",
    "\n",
    "# Device setting\n",
    "device = torch.device(\"cpu\")  # Your laptop does not have CUDA support, so using CPU\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# Step 1: Initialize model\n",
    "model = CNNTransformerModel(num_classes)\n",
    "\n",
    "# Step 2: Load model's state_dict (if available) with strict=False in case of missing keys\n",
    "try:\n",
    "    model.load_state_dict(torch.load(\"cnn_transformer_model.pth\", map_location=device), strict=False)\n",
    "    print(\"Model loaded successfully\")\n",
    "except RuntimeError as e:\n",
    "    print(\"Error loading model:\", e)\n",
    "\n",
    "# Step 3: Set the model to evaluation mode\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Optional: You can now run evaluations using the model\n",
    "# Example code to make predictions:\n",
    "# outputs = model(inputs)  # inputs should be a batch of data in tensor format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 78313,
     "sourceId": 182633,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
